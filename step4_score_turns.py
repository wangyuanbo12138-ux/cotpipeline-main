import os
import re
import time
import json
from pathlib import Path
from pydantic import BaseModel, Field

# å¤ç”¨å·²æœ‰çš„å·¥å…·
from utils.file_utils import read_jsonl, write_jsonl
from utils.api_utils import get_judge_client

# ================= é…ç½®åŒºåŸŸ =================

# 1. å®šä¹‰æ‰“åˆ†çš„æ•°æ®ç»“æž„ (ç›´æŽ¥å†™åœ¨è¿™é‡Œï¼Œä¸ç”¨æ”¹ utils æ–‡ä»¶äº†)
class ScoreSchema(BaseModel):
    """é’ˆå¯¹å•ä¸ª QA å¯¹çš„æ‰“åˆ†ç»“æžœ"""
    score: int = Field(..., description="æ ¹æ®è¯„åˆ†æ ‡å‡†ç»™å‡ºçš„åˆ†æ•° (0-10åˆ†)ã€‚")
    analysis: str = Field(..., description="å¯¹è¯¥è½®å¯¹è¯è´¨é‡çš„ç®€è¦åˆ†æžã€‚")

# 2. è¯„åˆ†æ ‡å‡† Prompt
SCORING_CRITERIA = """
ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„å¯¹è¯è´¨é‡æ‰“åˆ†å‘˜ã€‚è¯·å¯¹ã€AiMeã€‘çš„å›žå¤è¿›è¡Œæ‰“åˆ† (0-10åˆ†)ã€‚

ã€è¯„åˆ†æ ‡å‡†ã€‘
- **10åˆ† (å®Œç¾Ž)**ï¼šå›žå¤æžå…·å…±æƒ…åŠ›ï¼Œé€»è¾‘æ¸…æ™°ï¼Œä¸”å·§å¦™åœ°å¼•å¯¼äº†è¯é¢˜æˆ–è§£å†³äº†ç”¨æˆ·çš„æ½œåœ¨æƒ…ç»ªã€‚
- **8-9åˆ† (ä¼˜ç§€)**ï¼šå›žå¤è‡ªç„¶å¾—ä½“ï¼Œäººè®¾ä¿æŒè‰¯å¥½ï¼Œæ— æ˜Žæ˜¾ç‘•ç–µã€‚
- **6-7åˆ† (åˆæ ¼)**ï¼šå›žå¤ä¸­è§„ä¸­çŸ©ï¼Œèƒ½æŽ¥ä¸Šè¯ï¼Œä½†ç¼ºä¹äº®ç‚¹æˆ–ç•¥æ˜¾æœºæ¢°ã€‚
- **4-5åˆ† (å¹³åº¸)**ï¼šå›žå¤æœ‰â€œAIå‘³â€ï¼Œè¯´æ•™æ„Ÿå¼ºï¼Œæˆ–è€…é€»è¾‘æœ‰å°æ¼æ´žã€‚
- **0-3åˆ† (å·®åŠ²)**ï¼šå®Œå…¨ç­”éžæ‰€é—®ï¼Œé€»è¾‘æ··ä¹±ï¼Œæˆ–è€…äººè®¾å´©å¡Œï¼ˆå¦‚çªç„¶å˜æˆäº†å†·æ¼ çš„æœºå™¨ï¼‰ã€‚

ã€å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡ã€‘
{context}

ã€ç”¨æˆ· User è¯´ã€‘
{user_query}

ã€æ¨¡åž‹ AiMe å›žå¤ã€‘
{aime_response}
"""

# ================= æ ¸å¿ƒé€»è¾‘ =================

def parse_dialogue_to_turns(dialogue_text):
    """
    æŠŠé•¿æ–‡æœ¬æ‹†è§£ä¸ºæ¯ä¸€è½®ã€‚
    å…¼å®¹æ ¼å¼ï¼š
    1. ã€Userã€‘: ... ã€AiMeã€‘: ...
    2. User: ... AiMe: ...
    """
    turns = []
    
    # å°è¯•åŒ¹é… ã€Userã€‘ è¿™ç§æ ¼å¼
    pattern1 = re.compile(r"ã€Userã€‘:\s*(.*?)\s*\n\s*ã€AiMeã€‘:\s*(.*?)\s*(?=\nã€Userã€‘|$)", re.DOTALL)
    matches = pattern1.findall(dialogue_text)
    
    # å¦‚æžœæ²¡åŒ¹é…åˆ°ï¼Œå°è¯•åŒ¹é… User: è¿™ç§æ ¼å¼ (Batch ç”Ÿæˆæœ‰æ—¶ä¼šæ¼æŽ‰ã€ã€‘)
    if not matches:
        pattern2 = re.compile(r"User:\s*(.*?)\s*\n\s*AiMe:\s*(.*?)\s*(?=\nUser|$)", re.DOTALL)
        matches = pattern2.findall(dialogue_text)

    for m in matches:
        turns.append({
            "user": m[0].strip(),
            "aime": m[1].strip()
        })
    return turns

def score_one_turn(client, context, user, aime):
    """è°ƒç”¨è£åˆ¤ç»™å•ä¸ª Turn æ‰“åˆ†"""
    prompt = SCORING_CRITERIA.format(
        context=context if context else "(è¿™æ˜¯å¯¹è¯çš„ç¬¬ä¸€å¥)",
        user_query=user,
        aime_response=aime
    )
    
    try:
        # ä½¿ç”¨ Qwen æˆ– DeepSeek åšè£åˆ¤éƒ½å¯ä»¥
        result = client.chat.completions.create(
            model="qwen-max-latest", 
            response_model=ScoreSchema,
            messages=[
                {"role": "system", "content": "You are a critical dialogue quality evaluator."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0,
            max_retries=2
        )
        return result.score, result.analysis
    except Exception as e:
        print(f"  âŒ æ‰“åˆ†å‡ºé”™: {e}")
        return 0, "Error"

def process_file(file_path, output_path):
    print(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_path}")
    data = read_jsonl(file_path)
    if not data:
        print("âŒ æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥è·¯å¾„æˆ–å…ˆè¿è¡Œ Step 1")
        return

    client = get_judge_client()
    scored_data = []
    
    for i, sample in enumerate(data):
        # å…¼å®¹ä¸åŒæ¥æºçš„ question å­—æ®µ
        q_text = sample.get('question', 'æœªçŸ¥é—®é¢˜')
        print(f"\n[{i+1}/{len(data)}] æ­£åœ¨è¯„ä¼°å¯¹è¯: {q_text[:10]}...")
        
        dialogue_text = sample.get('dialogue_content', '')
        if not dialogue_text:
            print("  âš ï¸ å¯¹è¯å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡")
            continue

        turns = parse_dialogue_to_turns(dialogue_text)
        
        if not turns:
            print(f"  âš ï¸ æ— æ³•è§£æžå¯¹è¯æ ¼å¼ (æ­£åˆ™æœªåŒ¹é…)ï¼Œè·³è¿‡ã€‚")
            print(f"  (è°ƒè¯•) æ–‡æœ¬å‰50å­—: {dialogue_text[:50]}")
            continue
            
        turn_scores = []
        history_context = "" 
        detailed_turns = []

        for t_idx, turn in enumerate(turns):
            user_text = turn['user']
            aime_text = turn['aime']
            
            # æ‰“åˆ†
            score, reason = score_one_turn(client, history_context, user_text, aime_text)
            turn_scores.append(score)
            
            print(f"  - ç¬¬ {t_idx+1} è½®å¾—åˆ†: {score} | è¯„è¯­: {reason[:15]}...")
            
            detailed_turns.append({
                "turn_index": t_idx + 1,
                "user": user_text,
                "aime": aime_text,
                "score": score,
                "analysis": reason
            })
            
            history_context += f"User: {user_text}\nAiMe: {aime_text}\n"

        # ä½¿ç”¨å†…ç½®å¹³å‡é¿å…ä¾èµ– numpy
        avg_score = round(sum(turn_scores) / len(turn_scores), 2) if turn_scores else 0
        print(f"  âœ… è¯¥å¯¹è¯å¹³å‡åˆ†: {avg_score}")
        
        sample['avg_score'] = avg_score
        sample['turn_details'] = detailed_turns
        scored_data.append(sample)
        
        time.sleep(0.5)

    write_jsonl(scored_data, output_path)
    
    # è®¡ç®—æ•´ä½“å¹³å‡åˆ†
    all_avgs = [s['avg_score'] for s in scored_data]
    final_avg = round(sum(all_avgs) / len(all_avgs), 2) if all_avgs else 0
    print("="*60)
    print(f"ðŸ“„ æ–‡ä»¶ {os.path.basename(file_path)} å¤„ç†å®Œæˆï¼")
    print(f"ðŸ“Š ç»¼åˆå¹³å‡åˆ†: {final_avg}")
    print("="*60)

def main():
    import glob
    
    Path("outputs/judged").mkdir(parents=True, exist_ok=True)
    
    # è‡ªåŠ¨æ‰«ææ‰€æœ‰ jsonl æ–‡ä»¶
    raw_files = glob.glob("outputs/raw/*.jsonl")
    
    print(f"æ‰¾åˆ° {len(raw_files)} ä¸ªæ–‡ä»¶å¾…å¤„ç†:")
    for f in raw_files:
        print(f"  - {f}")
    print("-" * 50)
    
    for input_f in raw_files:
        # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å: data_xxx.jsonl -> score_xxx.jsonl
        filename = os.path.basename(input_f).replace("data_", "score_")
        output_f = f"outputs/judged/{filename}"
        process_file(input_f, output_f)

if __name__ == "__main__":
    main()